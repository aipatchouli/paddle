{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 简介\n",
    "本项目是参加飞桨常规赛：中文场景文字识别的项目，项目score为85.93141。\n",
    "\n",
    "生成的预测文件为work中的result.txt文件\n",
    "\n",
    "项目任务为识别包含中文文字的街景图片，准确识别图片中的文字\n",
    "\n",
    "本项目源于\n",
    "https://aistudio.baidu.com/aistudio/projectdetail/615795\n",
    "https://aistudio.baidu.com/aistudio/projectdetail/681670\n",
    "\n",
    "感谢开发者为开源社区做出的贡献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 赛题说明\n",
    "**赛题背景**\n",
    "\n",
    "中文场景文字识别技术在人们的日常生活中受到广泛关注，具有丰富的应用场景，如：拍照翻译、图像检索、场景理解等。然而，中文场景中的文字面临着包括光照变化、低分辨率、字体以及排布多样性、中文字符种类多等复杂情况。如何解决上述问题成为一项极具挑战性的任务。\n",
    "\n",
    "本次飞桨常规赛以 中文场景文字识别 为主题，由2019第二届中国AI+创新创业全国大赛降低难度而来，提供大规模的中文场景文字识别数据，旨在为研究者提供学术交流平台，进一步推动中文场景文字识别算法与技术的突破。\n",
    "\n",
    "**比赛任务**\n",
    "\n",
    "要求选手必须使用飞桨对图像区域中的文字行进行预测，返回文字行的内容。\n",
    "\n",
    "**数据集介绍**\n",
    "\n",
    "本次竞赛数据集共包括33万张图片，其中21万张图片作为训练集，12万张作为测试集。数据集采自中国街景，并由街景图片中的文字行区域（例如店铺标牌、地标等等）截取出来而形成。所有图像都经过一些预处理，将文字区域利用仿射变化，等比映射为一张高为48像素的图片，如下图1所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/fb3cf59747e04f0cb9adde6a5a1945b3d9ef82f3b7c14c98bf248eb1c3886a3f)\n",
    "\n",
    "\n",
    "(a) 标注：魅派集成吊顶\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/57d58a35e1f34278bdb013b3f945ab69cddacf37c7fe40deba3c124fa1249753)\n",
    "\n",
    "\n",
    "(b) 标注：母婴用品连锁\n",
    "图1\n",
    "\n",
    "**标注文件**\n",
    "\n",
    "平台提供的标注文件为.txt文件格式。样例如下：\n",
    "\n",
    "\n",
    "\n",
    "| h | w | name | value |\n",
    "| -------- | -------- | -------- |-------- |\n",
    "| 128 | 48 | img_1.jpg | 文本1|\n",
    "| 56\t| 48\t| img_2.jpg|\t文本2|\n",
    "其中，文件中的四列分别是图片的宽、高、文件名和文字标注。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 考虑到编译环境的影响，请注意 做代码审查时，需要严格按照步骤一步一步往下做，不能跳步执行，更不能直接预测结果，否则会报错\n",
    "# ** 第一步**\n",
    "\n",
    "# 安装第三方库\n",
    "\n",
    "* 注意：项目重启后，必须要重新安装如下相应的依赖。否则无法运行程序！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (4.36.1)\n",
      "Collecting paddlepaddle-gpu==1.7.1.post97\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/31/b0/54f9450eb71a23aad0edf69d52423529a09dcc4c0ffa650ff5ba1feb0572/paddlepaddle_gpu-1.7.1.post97-cp37-cp37m-manylinux1_x86_64.whl (251.6MB)\n",
      "\u001b[K     |████████████████████████████████| 251.6MB 111kB/s eta 0:00:019\n",
      "\u001b[?25hRequirement already satisfied: rarfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (3.1)\n",
      "Requirement already satisfied: objgraph in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (3.4.1)\n",
      "Requirement already satisfied: nltk; python_version >= \"3.5\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (3.4.5)\n",
      "Requirement already satisfied: numpy>=1.12; python_version >= \"3.5\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (1.16.4)\n",
      "Requirement already satisfied: funcsigs in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (1.0.2)\n",
      "Requirement already satisfied: prettytable in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (0.7.2)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (2.22.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (5.1.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (4.4.0)\n",
      "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (2.2.3)\n",
      "Requirement already satisfied: scipy<=1.3.1; python_version >= \"3.5\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (1.3.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (1.12.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (4.1.1.26)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (3.10.0)\n",
      "Requirement already satisfied: graphviz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (0.13)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (6.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.7.1.post97) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.7.1.post97) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.7.1.post97) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.7.1.post97) (3.0.4)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.7.1.post97) (2019.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.7.1.post97) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.7.1.post97) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.7.1.post97) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.7.1.post97) (2.4.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from protobuf>=3.1.0->paddlepaddle-gpu==1.7.1.post97) (41.4.0)\n",
      "Installing collected packages: paddlepaddle-gpu\n",
      "  Found existing installation: paddlepaddle-gpu 1.6.2.post97\n",
      "    Uninstalling paddlepaddle-gpu-1.6.2.post97:\n",
      "      Successfully uninstalled paddlepaddle-gpu-1.6.2.post97\n",
      "Successfully installed paddlepaddle-gpu-1.7.1.post97\n",
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Collecting pqi\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/33/a0/c446aed3d2a2aee6603baa430979c402859821a9bf02c23f59500171c9d2/pqi-2.0.6.tar.gz\n",
      "Collecting docopt (from pqi)\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz\n",
      "Building wheels for collected packages: pqi, docopt\n",
      "  Building wheel for pqi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pqi: filename=pqi-2.0.6-cp37-none-any.whl size=4442 sha256=bd24c7b42fbaf480d4d3f64b04f2d1959e194fdb3f388bbf8ddcc324be7b3988\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/54/76/37/bfae74b1d9f2b553cb45117a492ba3f567381e4f3ae307b5f6\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=b557c5ad908993d9ee1507d73583b162b166a2240dee201d441c9e7bb84f8272\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/51/86/5e/aca8b65bdc4038d6012e3bc45c33f438ec33a8582d8f2a7fbb\n",
      "Successfully built pqi docopt\n",
      "Installing collected packages: docopt, pqi\n",
      "Successfully installed docopt-0.6.2 pqi-2.0.6\n",
      "\n",
      "Source is changed to aliyun(https://mirrors.aliyun.com/pypi/simple/).\n",
      "\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (4.36.1)\n",
      "Collecting imgaug\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n",
      "\u001b[K     |████████████████████████████████| 952kB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lmdb\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/2e/dd/ada2fd91cd7832979069c556607903f274470c3d3d2274e0a848908272e8/lmdb-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (299kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.2.3)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (4.1.1.26)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (6.2.0)\n",
      "Collecting python-Levenshtein\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 2.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (5.1.2)\n",
      "Collecting trdg\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/76/55/4ce0f6e928200d3fe8460638346dcd2916d7aac33c7ebebbfec2b5eb7972/trdg-1.7.0-py3-none-any.whl (91.2MB)\n",
      "\u001b[K     |████████████████████████████████| 91.2MB 3.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting anyconfig\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/9b/8c/8f2dfad4f96ad0892fe5c1559d6a72ef0751c35d244779befe69d70de3a5/anyconfig-0.11.0-py2.py3-none-any.whl (81kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 4.8MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting scikit-image>=0.14.2 (from imgaug)\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/cd/d9/d738fdb4954575fb631b9c7a2eaa59df3ab8b7f3c2fc28a37259a42d8a49/scikit_image-0.18.2-cp37-cp37m-manylinux1_x86_64.whl (29.2MB)\n",
      "\u001b[K     |████████████████████████████████| 29.2MB 3.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: imageio in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (2.6.1)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.16.4)\n",
      "Collecting Shapely (from imgaug)\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/98/f8/db4d3426a1aba9d5dfcc83ed5a3e2935d2b1deb73d350642931791a61c37/Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 3.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from python-Levenshtein) (41.4.0)\n",
      "Collecting beautifulsoup4>=4.6.0 (from trdg)\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 3.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from trdg) (2.22.0)\n",
      "Collecting diffimg==0.2.3 (from trdg)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3d/fa/de925a7c2203b52f007ad6b9cce343c21dbe389a221a4f51f25960c83d8b/diffimg-0.2.3.tar.gz\n",
      "Collecting tifffile>=2019.7.26 (from scikit-image>=0.14.2->imgaug)\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/4f/b5/f668516b0250f1ad1156964bd2d1c6c3aa9f0178107a43fbe3258b0d3189/tifffile-2021.7.2-py3-none-any.whl (169kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 3.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1 (from scikit-image>=0.14.2->imgaug)\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/62/bd/592c7242fdd1218a96431512e77265c50812315ef72570ace85e1cfae298/PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4MB 3.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (2.4)\n",
      "Collecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4>=4.6.0->trdg)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->trdg) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->trdg) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->trdg) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->trdg) (1.25.6)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug) (4.4.0)\n",
      "Building wheels for collected packages: python-Levenshtein, diffimg\n",
      "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=163162 sha256=db83aaa37d45d70057158f2c4110383bceedc0c47a54f693b1bc0eb08756f5af\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/37/32/7f/d1b41ce17eb00f23e152a3da3cb4588e094d55b8f1f7d43159\n",
      "  Building wheel for diffimg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffimg: filename=diffimg-0.2.3-cp37-none-any.whl size=4050 sha256=23ec269313eb85624178acacbf323a9b705a86c4a6062917a546e86909b26cc7\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/70/b8/cf/783065bf363fd70e7a5a58dafd8b40667db51a8aa9f8935557\n",
      "Successfully built python-Levenshtein diffimg\n",
      "\u001b[31mERROR: scikit-image 0.18.2 has requirement numpy>=1.16.5, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: trdg 1.7.0 has requirement opencv-python>=4.2.0.32, but you'll have opencv-python 4.1.1.26 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: trdg 1.7.0 has requirement pillow>=7.0.0, but you'll have pillow 6.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tifffile, PyWavelets, scikit-image, Shapely, imgaug, lmdb, python-Levenshtein, soupsieve, beautifulsoup4, diffimg, trdg, anyconfig\n",
      "Successfully installed PyWavelets-1.1.1 Shapely-1.7.1 anyconfig-0.11.0 beautifulsoup4-4.9.3 diffimg-0.2.3 imgaug-0.4.0 lmdb-1.2.1 python-Levenshtein-0.12.2 scikit-image-0.18.2 soupsieve-2.2.1 tifffile-2021.7.2 trdg-1.7.0\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm paddlepaddle-gpu==1.7.1.post97 -i https://mirror.baidu.com/pypi/simple\r\n",
    "! pip install pqi\r\n",
    "! pqi use aliyun\r\n",
    "! pip install tqdm imgaug lmdb matplotlib opencv-python Pillow python-Levenshtein PyYAML trdg anyconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ** 第二步**\n",
    "\n",
    "# 解压文件\n",
    "\n",
    "* 项目重启后，必须要重新解压数据，压缩包内含训练集图片、训练集图片信息、测试集图片， 否则无法运行本程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  inflating: test_images/1376.jpg    \r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/aistudio/data/data10879')\n",
    "! rm -rf /test_images/\n",
    "os.chdir('/home/aistudio/work')\n",
    "! unzip test_images.zip\n",
    "! mv /home/aistudio/work/test_images/ /home/aistudio/data/data10879\n",
    "! rm -rf /home/aistudio/work/__MACOSX/\n",
    "! rm -rf /home/aistudio/work/test_images/\n",
    "os.chdir('/home/aistudio/data/data10879')\n",
    "! rm -rf /train_img/\n",
    "! tar -zxf train_img.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ** 第三步**\n",
    "\n",
    "# 预处理\n",
    "\n",
    "* 项目重启后，需要重新做数据预处理\n",
    "* 文件 langconv(language convert)，这个文件用来把繁体字转成简体字<br>\n",
    "\n",
    "* 函数 read_ims_list：读取train.list文件，生成图片的信息字典\n",
    "* 函数 modify_ch：对标签label进行修改，进行四项操作，分别是“繁体->简体”、“大写->小写”、“删除空格”、“删除符号”。\n",
    "* 函数 pipeline：调用定义的函数，对训练数据进行初步处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class num: 3827\n",
      "训练集数量: 200342, 验证集数量: 10544\n"
     ]
    }
   ],
   "source": [
    "from work.langconv import Converter\n",
    "import codecs\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "\n",
    "os.chdir('/home/aistudio')\n",
    "sys.path.append('/home/aistudio/work')\n",
    "def read_ims_list(path_ims_list):\n",
    "    \"\"\"\n",
    "    读取 train.list 文件\n",
    "    \"\"\"\n",
    "    ims_info_dic = {}\n",
    "    with open(path_ims_list, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=3)\n",
    "            w, h, file, label = parts[0], parts[1], parts[2], parts[3]\n",
    "            ims_info_dic[file] = {'label': label, 'w': int(w)}\n",
    "    return ims_info_dic\n",
    "    \n",
    "\n",
    "def modify_ch(label):\n",
    "    # 繁体 -> 简体\n",
    "    label = Converter(\"zh-hans\").convert(label)\n",
    "\n",
    "    # 大写 -> 小写\n",
    "    label = label.lower()\n",
    "\n",
    "    # 删除空格\n",
    "    label = label.replace(' ', '')\n",
    "\n",
    "    # 删除符号\n",
    "    for ch in label:\n",
    "        if (not '\\u4e00' <= ch <= '\\u9fff') and (not ch.isalnum()):\n",
    "            label = label.replace(ch, '')\n",
    "\n",
    "    return label\n",
    "\n",
    "def save_txt(data, file_path):\n",
    "    \"\"\"\n",
    "    将一个list的数组写入txt文件里\n",
    "    :param data:\n",
    "    :param file_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not isinstance(data, list):\n",
    "        data = [data]\n",
    "    with open(file_path, mode='w', encoding='utf8') as f:\n",
    "        f.write('\\n'.join(data))\n",
    "\n",
    "def pipeline(dataset_dir):\n",
    "    path_ims        = pjoin(dataset_dir, \"train_images\")\n",
    "    path_ims_list   = pjoin(dataset_dir, \"train.list\")\n",
    "    path_train_list = pjoin('/home/aistudio/work', \"train.txt\")\n",
    "    path_test_list  = pjoin('/home/aistudio/work', \"test.txt\")\n",
    "    path_label_list = pjoin('/home/aistudio/work', \"dict.txt\")\n",
    "\n",
    "    # 读取数据信息\n",
    "    file_info_dic = read_ims_list(path_ims_list)\n",
    "\n",
    "    # 创建 train.txt\n",
    "    class_set = set()\n",
    "    data_list = []\n",
    "    for file, info in file_info_dic.items():\n",
    "        label = info['label']\n",
    "        label = modify_ch(label)\n",
    "\n",
    "        # 异常: 标签为空\n",
    "        if label == '':\n",
    "            continue\n",
    "\n",
    "        for e in label:\n",
    "            class_set.add(e)\n",
    "        data_list.append(\"{0}\\t{1}\".format(pjoin('/home/aistudio/',path_ims, file), label))\n",
    "        \n",
    "    # 创建 label_list.txt\n",
    "    class_list = list(class_set)\n",
    "    class_list.sort()\n",
    "    print(\"class num: {0}\".format(len(class_list)))\n",
    "    with codecs.open(path_label_list, \"w\", encoding='utf-8') as label_list:\n",
    "        for id, c in enumerate(class_list):\n",
    "            # label_list.write(\"{0}\\t{1}\\n\".format(c, id))\n",
    "            label_list.write(\"{0}\\n\".format(c))\n",
    "\n",
    "    # 随机切分\n",
    "    random.shuffle(data_list)\n",
    "    val_len = int(len(data_list) * 0.05)\n",
    "    val_list = data_list[-val_len:]\n",
    "    train_list = data_list[:-val_len]\n",
    "    print('训练集数量: {}, 验证集数量: {}'.format(len(train_list),len(val_list)))\n",
    "    save_txt(train_list,path_train_list)\n",
    "    save_txt(val_list,path_test_list)\n",
    "    \n",
    "random.seed(0)\n",
    "pipeline(dataset_dir=\"data/data10879\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 特别说明\n",
    "\n",
    "对于PaddleOCR提供的配置文件rec_r34_vd_none_bilstm_ctc.yml我做出了如下修改\n",
    "\n",
    "1.将epoch_num改为30\n",
    "\n",
    "2.将train_batch_size_per_card改为256\n",
    "\n",
    "3.将test_batch_size_per_card改为128\n",
    "\n",
    "4.将base_lr改为0.00001\n",
    "\n",
    "经测试这样能提高score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ** 第四步**\n",
    "\n",
    "# 模型训练\n",
    "\n",
    "*注意 项目重启后，必须要切换主目录至/home/aistudio/work/PaddleOCR, 如果训练的模型不存在了，需要先训练模型  否则无法调用模型进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work/PaddleOCR\n",
      "2021-07-20 11:27:20,974-INFO: {'Global': {'algorithm': 'CRNN', 'use_gpu': True, 'epoch_num': 30, 'log_smooth_window': 20, 'print_batch_step': 100, 'save_model_dir': 'output/rec_CRNN_aug_341', 'save_epoch_step': 1, 'eval_batch_step': 1800, 'train_batch_size_per_card': 256, 'test_batch_size_per_card': 128, 'image_shape': [3, 32, 256], 'max_text_length': 64, 'character_type': 'ch', 'loss_type': 'ctc', 'reader_yml': './configs/rec/rec_icdar15_reader.yml', 'pretrain_weights': '/home/aistudio/work/PaddleOCR/model/latest', 'checkpoints': None, 'save_inference_dir': '/home/aistudio/work/test', 'character_dict_path': '/home/aistudio/work/dict.txt'}, 'Architecture': {'function': 'ppocr.modeling.architectures.rec_model,RecModel'}, 'Backbone': {'function': 'ppocr.modeling.backbones.rec_resnet_vd,ResNet', 'layers': 34}, 'Head': {'function': 'ppocr.modeling.heads.rec_ctc_head,CTCPredict', 'encoder_type': 'rnn', 'SeqRNN': {'hidden_size': 256}}, 'Loss': {'function': 'ppocr.modeling.losses.rec_ctc_loss,CTCLoss'}, 'Optimizer': {'function': 'ppocr.optimizer,AdamDecay', 'base_lr': 1e-05, 'beta1': 0.9, 'beta2': 0.999}, 'TrainReader': {'reader_function': 'ppocr.data.rec.dataset_traversal,SimpleReader', 'num_workers': 8, 'img_set_dir': '/', 'label_file_path': '/home/aistudio/work/train.txt'}, 'EvalReader': {'reader_function': 'ppocr.data.rec.dataset_traversal,SimpleReader', 'img_set_dir': '/', 'label_file_path': '/home/aistudio/work/test.txt'}, 'TestReader': {'reader_function': 'ppocr.data.rec.dataset_traversal,SimpleReader', 'infer_img': '/home/aistudio/data/data10879/test_images'}}\n",
      "import ujson error: No module named 'ujson' use json\n",
      "2021-07-20 11:27:24,394-INFO: places would be ommited when DataLoader is not iterable\n",
      "W0720 11:27:25.270781   313 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 9.0\n",
      "W0720 11:27:25.275805   313 device_context.cc:245] device: 0, cuDNN Version: 7.3.\n",
      "2021-07-20 11:27:27,081-INFO: Loading parameters from /home/aistudio/work/PaddleOCR/model/latest...\n",
      "2021-07-20 11:27:28,142-INFO: Finish initing model from /home/aistudio/work/PaddleOCR/model/latest\n",
      "I0720 11:27:28.165637   313 parallel_executor.cc:440] The Program will be executed on CUDA using ParallelExecutor, 1 cards are used, so 1 programs are executed in parallel.\n",
      "I0720 11:27:28.190510   313 build_strategy.cc:365] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0720 11:27:28.223546   313 parallel_executor.cc:307] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0720 11:27:28.241607   313 parallel_executor.cc:375] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "2021-07-20 11:30:12,289-INFO: epoch: 0, iter: 100, lr: 0.000010, 'loss': 907.36426, 'acc': 0.734375, time: 1.533\n",
      "2021-07-20 11:32:46,499-INFO: epoch: 0, iter: 200, lr: 0.000010, 'loss': 839.9638, 'acc': 0.734375, time: 1.546\n",
      "2021-07-20 11:35:21,331-INFO: epoch: 0, iter: 300, lr: 0.000010, 'loss': 875.3085, 'acc': 0.746094, time: 1.549\n",
      "2021-07-20 11:37:56,389-INFO: epoch: 0, iter: 400, lr: 0.000010, 'loss': 876.96655, 'acc': 0.748047, time: 1.550\n",
      "2021-07-20 11:40:31,384-INFO: epoch: 0, iter: 500, lr: 0.000010, 'loss': 792.8467, 'acc': 0.748047, time: 1.551\n",
      "2021-07-20 11:43:06,349-INFO: epoch: 0, iter: 600, lr: 0.000010, 'loss': 866.082, 'acc': 0.755859, time: 1.548\n",
      "2021-07-20 11:45:41,223-INFO: epoch: 0, iter: 700, lr: 0.000010, 'loss': 864.1907, 'acc': 0.75, time: 1.551\n",
      "2021-07-20 11:47:50,902-INFO: Already save model in output/rec_CRNN_aug_341/latest\n",
      "2021-07-20 11:48:21,235-INFO: epoch: 1, iter: 800, lr: 0.000010, 'loss': 760.35156, 'acc': 0.746856, time: 1.718\n",
      "2021-07-20 11:51:02,742-INFO: epoch: 1, iter: 900, lr: 0.000010, 'loss': 872.21704, 'acc': 0.755859, time: 1.549\n",
      "2021-07-20 11:53:37,457-INFO: epoch: 1, iter: 1000, lr: 0.000010, 'loss': 958.0448, 'acc': 0.751953, time: 1.556\n",
      "2021-07-20 11:56:12,343-INFO: epoch: 1, iter: 1100, lr: 0.000010, 'loss': 860.2683, 'acc': 0.740234, time: 1.548\n",
      "2021-07-20 11:58:46,932-INFO: epoch: 1, iter: 1200, lr: 0.000010, 'loss': 762.4317, 'acc': 0.753906, time: 1.547\n",
      "2021-07-20 12:01:21,949-INFO: epoch: 1, iter: 1300, lr: 0.000010, 'loss': 778.70435, 'acc': 0.761719, time: 1.551\n",
      "2021-07-20 12:03:57,037-INFO: epoch: 1, iter: 1400, lr: 0.000010, 'loss': 896.6123, 'acc': 0.742188, time: 1.543\n",
      "2021-07-20 12:06:31,867-INFO: epoch: 1, iter: 1500, lr: 0.000010, 'loss': 838.49994, 'acc': 0.746094, time: 1.545\n",
      "2021-07-20 12:08:16,518-INFO: Already save model in output/rec_CRNN_aug_341/latest\n",
      "2021-07-20 12:09:14,099-INFO: epoch: 2, iter: 1600, lr: 0.000010, 'loss': 760.04846, 'acc': 0.742188, time: 1.599\n",
      "2021-07-20 12:11:54,944-INFO: epoch: 2, iter: 1700, lr: 0.000010, 'loss': 896.3973, 'acc': 0.757812, time: 1.541\n",
      "^C\n",
      "pid 1913 terminated, terminate group 312...\n",
      "pid 1912 terminated, terminate group 312...\n",
      "pid 1915 terminated, terminate group 312...\n",
      "pid 1910 terminated, terminate group 312...\n",
      "pid 1909 terminated, terminate group 312...\n",
      "pid 1911 terminated, terminate group 312...\n",
      "pid 1908 terminated, terminate group 312...\n",
      "pid 1907 terminated, terminate group 312...\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "os.chdir('/home/aistudio/work/PaddleOCR/')\r\n",
    "! pwd\r\n",
    "! export PYTHONPATH=$PYTHONPATH:.\r\n",
    "! python tools/train.py -c configs/rec/rec_r34_vd_none_bilstm_ctc.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ** 第五步**\n",
    "\n",
    "# 模型预测\n",
    "\n",
    "* 项目重启后，如果训练好的模型已经存在，则可以直接调用之前训练好的模型直接进行推理即可，如果训练的模型不存在，一般要执行训练模型的步骤，先训练好模型  然后才可以调用模型进行预测，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work/PaddleOCR\n",
      "2021-07-20 12:14:04,280-INFO: {'Global': {'algorithm': 'CRNN', 'use_gpu': True, 'epoch_num': 30, 'log_smooth_window': 20, 'print_batch_step': 100, 'save_model_dir': 'output/rec_CRNN_aug_341', 'save_epoch_step': 1, 'eval_batch_step': 1800, 'train_batch_size_per_card': 256, 'test_batch_size_per_card': 128, 'image_shape': [3, 32, 256], 'max_text_length': 64, 'character_type': 'ch', 'loss_type': 'ctc', 'reader_yml': './configs/rec/rec_icdar15_reader.yml', 'pretrain_weights': '/home/aistudio/work/PaddleOCR/model/latest', 'checkpoints': 'output/rec_CRNN_aug_341/latest', 'save_inference_dir': '/home/aistudio/work/test', 'character_dict_path': '/home/aistudio/work/dict.txt'}, 'Architecture': {'function': 'ppocr.modeling.architectures.rec_model,RecModel'}, 'Backbone': {'function': 'ppocr.modeling.backbones.rec_resnet_vd,ResNet', 'layers': 34}, 'Head': {'function': 'ppocr.modeling.heads.rec_ctc_head,CTCPredict', 'encoder_type': 'rnn', 'SeqRNN': {'hidden_size': 256}}, 'Loss': {'function': 'ppocr.modeling.losses.rec_ctc_loss,CTCLoss'}, 'Optimizer': {'function': 'ppocr.optimizer,AdamDecay', 'base_lr': 1e-05, 'beta1': 0.9, 'beta2': 0.999}, 'TrainReader': {'reader_function': 'ppocr.data.rec.dataset_traversal,SimpleReader', 'num_workers': 8, 'img_set_dir': '/', 'label_file_path': '/home/aistudio/work/train.txt'}, 'EvalReader': {'reader_function': 'ppocr.data.rec.dataset_traversal,SimpleReader', 'img_set_dir': '/', 'label_file_path': '/home/aistudio/work/test.txt'}, 'TestReader': {'reader_function': 'ppocr.data.rec.dataset_traversal,SimpleReader', 'infer_img': '/home/aistudio/data/data10879/test_images'}}\n",
      "W0720 12:14:05.592820  6342 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 9.0\n",
      "W0720 12:14:05.597887  6342 device_context.cc:245] device: 0, cuDNN Version: 7.3.\n",
      "2021-07-20 12:14:08,492-INFO: Finish initing model from output/rec_CRNN_aug_341/latest\n",
      "  7%|██▋                                    | 704/10000 [00:22<04:51, 31.91it/s]"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "os.chdir('/home/aistudio/work/PaddleOCR/')\r\n",
    "! pwd\r\n",
    "! export PYTHONPATH=$PYTHONPATH:.\r\n",
    "! python tools/infer_rec.py -c configs/rec/rec_r34_vd_none_bilstm_ctc.yml -o Global.checkpoints=output/rec_CRNN_aug_341/latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **方案说明书**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " # 1. 比赛介绍+赛题重点难点剖析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* 比赛介绍：本项目是参加飞桨常规赛：中文场景文字识别的项目，项目任务为识别包含中文文字的街景图片，准确识别图片中的文字。\n",
    "\n",
    "* 赛题重点难点剖析：中文场景中的文字面临着包括光照变化、低分辨率、字体以及排布多样性、中文字符种类多等复杂情况。如何解决上述问题成为一项极具挑战性的任务。此外，从自然场景图片中进行文字识别，需要包括2个步骤： 1）文字检测：解决的问题是哪里有文字，文字的范围有多少？ 2）文字识别：对定位好的文字区域进行识别，主要解决的问题是每个文字是什么，将图像中的文字区域进转化为字符信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2.  思路介绍+方案亮点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* 思路介绍：第一步是针对中文场景下的数据预处理（包括：把繁体字转成简体字，大写->小写，删除空格，删除符号等操作），结合相应的中文字典来提升文字识别的准确率。第二步是在飞桨框架下采用当前业界最经典的CRNN算法架构来建模与求解，以保证模型的性能。\n",
    "\n",
    "* 方案亮点：结合中文场景下的字典资源来完成数据的预处理，可以更好的构建训练模型的语料；参考了Tensorflow版本的CRNN模型的代码，然后将其改造并迁移到飞桨平台，使其与国产化平台相适配；采用CRNN架构下的rec_r34_vd_none_bilstm_ctc模型来建模与求解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3. 具体方案分享"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*   ![](https://ai-studio-static-online.cdn.bcebos.com/c8caa0ae233c4d338e0535dee67e54d5fec4f310e45e4abda27862b7261b65c6)\n",
    "*   图1文字识别的流程图\n",
    "*  上图展示了整个识别过程的流程，CRNN模型的框架和相应超参数设置如下所示：\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c5101a24814b4965b59e05e76f4fafc8800412f242124e35a1aaaf77aac57b07)\n",
    "* 图2：RCNN模型的网络层次结构图\n",
    "* Global:\n",
    "  algorithm: CRNN\n",
    "  use_gpu: true\n",
    "  epoch_num: 30\n",
    "  log_smooth_window: 20\n",
    "  print_batch_step: 100\n",
    "  save_model_dir: output/rec_CRNN_aug_341\n",
    "  save_epoch_step: 1\n",
    "  eval_batch_step: 1800\n",
    "  train_batch_size_per_card: 256\n",
    "  test_batch_size_per_card: 128\n",
    "  image_shape: [3, 32, 256]\n",
    "  max_text_length: 64\n",
    "  character_type: ch\n",
    "  loss_type: ctc\n",
    "  reader_yml: ./configs/rec/rec_icdar15_reader.yml\n",
    "  pretrain_weights: /home/aistudio/work/PaddleOCR/model/latest\n",
    "  checkpoints: \n",
    "  save_inference_dir: /home/aistudio/work/test\n",
    "  character_dict_path: /home/aistudio/work/dict.txt\n",
    "* Architecture:\n",
    "  function: ppocr.modeling.architectures.rec_model,RecModel\n",
    "* Backbone:\n",
    "  function: ppocr.modeling.backbones.rec_resnet_vd,ResNet\n",
    "  layers: 34\n",
    "* Head:\n",
    "  function: ppocr.modeling.heads.rec_ctc_head,CTCPredict\n",
    "  encoder_type: rnn\n",
    "  SeqRNN: \n",
    "* hidden_size: 256\n",
    "* Loss:\n",
    "  function: ppocr.modeling.losses.rec_ctc_loss,CTCLoss\n",
    "* Optimizer:\n",
    "  function: ppocr.optimizer,AdamDecay\n",
    "  base_lr: 0.00001\n",
    "  beta1: 0.9\n",
    "  beta2: 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 4. 模型应用结果分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* 不同模型结果的对比分析：\n",
    "\n",
    "| 模型名称 | score | norm_distance |word_acc |\n",
    "| -------- | -------- | -------- | -------- |\n",
    "| 官方基线模型（PaddleOCR：中文场景文字识别）| 82.87     | 0.93946     | 0.82872     |\n",
    "|CRNN rec_r34_vd_none_bilstm_ctc | 85.94     | 0.95722     | 0.85941     |\n",
    "* 调参优化过程分析\n",
    "1. 将epoch_num改为30 \n",
    "2. 将train_batch_size_per_card改为256 \n",
    "3. 将test_batch_size_per_card改为128 \n",
    "4. 将base_lr改为0.00001 经测试这样能提高score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 5.  总结+改进完善方向"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* 总结 \n",
    " 通过参加本次比赛，大大的扩宽了自己的眼界，对模型有更加深刻的认识，可以根据不同的应用场景，去阅读国内外最新的文献，并将相关算法进行改造用以解决实际问题。在中文场景文字识别任务上，可以采用本模型来解决相关实际问题。\n",
    "* 改进完善方向\n",
    "1.  CNN部分目前用的RESNET，后续可以考虑改成VGG网络；\n",
    "2.  可以进一步加大高质量的标注数据集来训练模型，以增强模型的泛化性能；\n",
    "3.  后续可以进一步优化损失函数和训练策略，以便提升模型的收敛速度。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  7.  参考资料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. EAST:\n",
    "@inproceedings{zhou2017east,\n",
    "  title={EAST: an efficient and accurate scene text detector},\n",
    "  author={Zhou, Xinyu and Yao, Cong and Wen, He and Wang, Yuzhi and Zhou, Shuchang and He, Weiran and Liang, Jiajun},\n",
    "  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},\n",
    "  pages={5551--5560},\n",
    "  year={2017}\n",
    "}\n",
    "\n",
    "2. DB:\n",
    "@article{liao2019real,\n",
    "  title={Real-time Scene Text Detection with Differentiable Binarization},\n",
    "  author={Liao, Minghui and Wan, Zhaoyi and Yao, Cong and Chen, Kai and Bai, Xiang},\n",
    "  journal={arXiv preprint arXiv:1911.08947},\n",
    "  year={2019}\n",
    "}\n",
    "\n",
    "3. DTRB:\n",
    "@inproceedings{baek2019wrong,\n",
    "  title={What is wrong with scene text recognition model comparisons? dataset and model analysis},\n",
    "  author={Baek, Jeonghun and Kim, Geewook and Lee, Junyeop and Park, Sungrae and Han, Dongyoon and Yun, Sangdoo and Oh, Seong Joon and Lee, Hwalsuk},\n",
    "  booktitle={Proceedings of the IEEE International Conference on Computer Vision},\n",
    "  pages={4715--4723},\n",
    "  year={2019}\n",
    "}\n",
    "\n",
    "4. SAST:\n",
    "@inproceedings{wang2019single,\n",
    "  title={A Single-Shot Arbitrarily-Shaped Text Detector based on Context Attended Multi-Task Learning},\n",
    "  author={Wang, Pengfei and Zhang, Chengquan and Qi, Fei and Huang, Zuming and En, Mengyi and Han, Junyu and Liu, Jingtuo and Ding, Errui and Shi, Guangming},\n",
    "  booktitle={Proceedings of the 27th ACM International Conference on Multimedia},\n",
    "  pages={1277--1285},\n",
    "  year={2019}\n",
    "}\n",
    "\n",
    "5. SRN:\n",
    "@article{yu2020towards,\n",
    "  title={Towards Accurate Scene Text Recognition with Semantic Reasoning Networks},\n",
    "  author={Yu, Deli and Li, Xuan and Zhang, Chengquan and Han, Junyu and Liu, Jingtuo and Ding, Errui},\n",
    "  journal={arXiv preprint arXiv:2003.12294},\n",
    "  year={2020}\n",
    "}\n",
    "\n",
    "6. end2end-psl:\n",
    "@inproceedings{sun2019chinese,\n",
    "  title={Chinese Street View Text: Large-scale Chinese Text Reading with Partially Supervised Learning},\n",
    "  author={Sun, Yipeng and Liu, Jiaming and Liu, Wei and Han, Junyu and Ding, Errui and Liu, Jingtuo},\n",
    "  booktitle={Proceedings of the IEEE International Conference on Computer Vision},\n",
    "  pages={9086--9095},\n",
    "  year={2019}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.6.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
